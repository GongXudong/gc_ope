type: ppo
policy: MultiInputPolicy  # MultiInputPolicy, MlpPolicy, CnnPolicy
seed: 2
batch_size: 512
gamma: 0.95
n_steps: 512
n_epochs: 5
ent_coef: 0.0
net_arch: [256, 256]
use_sde: true
normalize_advantage: true
learning_rate_decay: true
learning_rate: 3e-4
device: cpu